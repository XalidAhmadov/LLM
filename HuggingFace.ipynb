{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o1NyAf5dobQD"
   },
   "source": [
    "##Hugging Face library with Chain of Thought"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uUCFPhlSokGe"
   },
   "source": [
    "Install Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iMTyxcR7MAXi"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install transformers>=4.41.2 accelerate>=0.31.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q-xn3FQHouZ9"
   },
   "source": [
    "Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_-3fpSkDotyd"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GEo6P-oSoyCZ"
   },
   "source": [
    "Load the tokenizer and model and Create a text-generation pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 745,
     "referenced_widgets": [
      "297a9974d1ca46a69e03bdddb90c2c1b",
      "8a1d3d76b3d04aa1baff94578db03e3e",
      "107d85ec8df64242b59eb70ee9915e19",
      "e6e44f61c5dd46b3946b2c4797de2929",
      "825d472186d8471ca59d1b05b4ed44c4",
      "32a6144be5ec40779e9e9ab1f484276b",
      "5a698447a5bd4851a34311cbd80b415e",
      "b01db4674174424e8203d852a1714044",
      "4b469012efe046309eba5e4ebf361582",
      "37721d81985440dfbd505faa27a50928",
      "3eb77dd8945440b18baad99a0425501d",
      "90d95997ef404a048e28c1480532f564",
      "3c93e0b547db40858c18c0d35b03507c",
      "a589e1e097e64ee396f08707c4502c44",
      "d2ab67da2fb14e80adee459a0e00ff7d",
      "afeac43981c54dee9826e584dadbdcec",
      "56bf98d152ca437896bdc4540416572c",
      "2d7bbb689faa47a6abce892b616fb614",
      "69e4d7e80a3e4fe2aafbd2fae63b75ca",
      "bde3e7de88664ac6bde56ff8ea296916",
      "2f7c614867d24709ace417d9f8aee719",
      "fc68d1ea903147288cde6c4d90da8f3a",
      "1c5fc7eb8d534ec3b1edc9b6327d70cf",
      "b9982bab6a604b8f97feb91a25ceb586",
      "adabfe248b014d35acf5bee168a5df13",
      "1fcef8a0681d4e0981d7a88b592c3194",
      "17d680048e474c34b0acbbfed5692da9",
      "81139380604b45c38aa828bbf7435e89",
      "62c201f499624bf2babeb01f688bb54c",
      "0c9412b987464433bfcfe836f96e001e",
      "5fafd5589c8145249bbfa4d68b1d1fb2",
      "2bb2882201424f9abdff3aeb1f73e49c",
      "0db0d1849fef4cd48930f3785e62e0d9",
      "691a1d4a5c014e17b3515cc4223399f1",
      "11f85fbfe4dd4fb1ad812f75f6b0db31",
      "6226ec72bd26450aa3c5066db2f2fac8",
      "e879a4a4d09b4b449b1bd784160ff8ae",
      "2b25a98dae634397b68a43b6a8d0ba95",
      "de0e19d264894b0ca85d98c5ddb0fb9e",
      "fe30c4abeb5b4a1a92009e5cefd8af1b",
      "c7101838bb85444cab59d42a60585708",
      "95fcbb9c72884ee791a4fcecc77eda83",
      "f55c451b2ddb4d2ab3d43e931dc70676",
      "eba6b1a6bc084917a4b0c4e6362343f8",
      "3afa232f229a4062bb7e920ef252f5c1",
      "d60ce4c9599749158e4ebdb55d1ab492",
      "59324a8a35a84bdfa86bb0058429cf20",
      "deddddcc1f0c41f2b762f1c6bbde3a06",
      "113bb9863fa246bf9d170b688ec3f304",
      "9f748bb73ec54300971bd40332af23dc",
      "99b8cbab30124fb5aebff728d1755694",
      "5d52927373344bc3be11503cf2fa1c68",
      "e30e6a8cec1645219464566917b13085",
      "a016f142af2643918f6c8b35eb864ac1",
      "46d309a5061c46809a7459215a78b80e",
      "8372875c033a4285a01b6e3b539566f0",
      "4aadbb099d004eadafc5720f1d7fc1c3",
      "af9338131eeb45fa8da90383e806e8c1",
      "d61fd9c6f6da4b53b685ad86c77fcac3",
      "e94f98d55e49429e803f69436fb68f36",
      "89bbd19ada1a4a0a9ecb23daf738a2f5",
      "98c7ae58d4e94db9a75456fd7cf65ec4",
      "ef6840326cda45cd9882b2dba051975f",
      "7614da27bbb0410793baf7c8aec1b11d",
      "d287baffcbcd4dfcb24d5b4e5c38384c",
      "63f8ebf03400497e9447498fec516ed4",
      "bf0c005ce2964448a779a9c5ac7a530c",
      "5efcbc26226a4748af2b961f7443a4bb",
      "da8501641dd44d599702104c07533fda",
      "7cc4513a1ad34b50a90defefdad637df",
      "cf1a4d35d1d94d6eb97b3d5df0fe4772",
      "4593aae5e5a24c59b5f140e8a03ebf75",
      "b1f3453625da40cb8ab9d9b8d0ed258d",
      "a4b15aa1bc5b4d1086b156465c1023cd",
      "9302952c58b344869aa4466891e986f5",
      "a2fca176f8cf4769bc5e0389d6370e6d",
      "c3b0cc998a74442885f23374c6e7caaf",
      "364c5ed256f7483fb6c9094aabca53ab",
      "e7b2828406bd4ca2b686bee600a69299",
      "12e78f9315d54f16b223eeb1a9b94ed5",
      "72682fce13134fec8f683b12302f6d02",
      "f3122e1dcd374571b1f44f637a2949ea",
      "8206e00fac1848e097e01042bddee15a",
      "48e9e790ddde47ff8a2ddc16be26434e",
      "e958d808d7e84a9a9caa4eee7b5c5da3",
      "209c0ee5750f4bc68347fcbbca590388",
      "f1ce239cc0664cd7b3f490c7757f4584",
      "28dec04f956449888b59803f2f604d6f",
      "6c50ecf233a14cdf831453be0e710572",
      "847941c55596425d8c87224e214acafd",
      "2db400094c654c73a17c5dfb0cfa645c",
      "c0bd0e2166964f83beadfa21a777cb95",
      "e68fc09954c54b5a9e095026ed102215",
      "54244772830b424c9a6c1056529c975a",
      "a05df91632c2474c98c1130ed7228649",
      "e825ea82adcd434eb78f7342b8fb6d79",
      "9433e925b3a0466faa94a52691d1bf50",
      "3f4e0be6f93a4338bf2dace20a2ff93e",
      "1f5583f69bb04b11b20f67717b53f99a",
      "118b3109dcdd4921bdc465fa8a539eac",
      "bd6e25990d3f452e9060ada0b93d8850",
      "451ae923c45446509be38b5304586549",
      "71a34c1ceae64d5391a11de5a96d734f",
      "fc7b8b70d16142a69b281dd7185ac5a2",
      "e7e3bdaaa64e4444a653ab70b341b54e",
      "efb72a6b419241e1b2cec3ff844a1cd9",
      "17a62483a27b415d8c75cb054cfe8a9d",
      "d92ccde40d544bf7ae6a9f846f5e76e7",
      "dcac780931c34222b3c57e15bb1d68a2",
      "695e7b03534849c089d80eba4e4ac6c0",
      "3a569dbe208d4a15a5bba01e45431488",
      "11b20b74b0b34d57b24040651782758b",
      "a05a078572584572956a24c0587f5700",
      "02707d6fdd50405d9abfb0803a85f15a",
      "280af02eaa1d4f2a9115bbcc9881a038",
      "1d68c567a7224fa9871b6f7c5f0b257c",
      "8f86eb4123bc49808d4cb6a8a461f8e3",
      "004ef61fd3de4aa7b46b323135c9515d",
      "9681ec12832640558ae25ff49aa5e1e2",
      "c00074ef67bf4158877c8eb113c0b69c",
      "c0085cdb227b407e92409a12b68a6d43",
      "f37dafe0b082448cb1770d2b9180f2b3",
      "5d7699766cbd447b9db0d5a96ab7dd01",
      "43882ea7008b4d00bb98b7878b978e11",
      "f213c497d6b0443cb7818b0484222546",
      "b54d64ce0e7241939307fbd92b432f64",
      "cefbe3d97631441699f7b0dd525b343d",
      "f916dd6202ea40f18d6c058b21149411",
      "530ce3c2e5c34a85b842273b69eeef46",
      "ef6e8d36c53e4c85930598bc573e6832",
      "e77c5394d04743119539dffa0c727967",
      "07678c9454b94a45b925b22fe9bcb261",
      "7700466829a946b2b4c340ce5ef0b314",
      "6757dac0dfd64d42b821117c4a2db7bb",
      "ddaca8a007f04c45b3c815ceeb51a5d3",
      "2e272c12040f48889685942f2e0b6596",
      "1090eb6571894c7ab8c6585c3dab0b03",
      "cd7ed57029154b8aa2ba11b0c1366353",
      "b07d31b4cc91431db9712ab9d0e0d456",
      "4447fd8a05b242468f53028b1d27438c",
      "3e5c6be0c8c846b8bb4743991a269cb9",
      "413a31e51aa14ad2b0d414e0da91530e",
      "86f7ce5fb744455897252e41fbc33c10",
      "90de2e827dbb402fbe1dc6d4c935822b",
      "b4f8ed2dffcb4bb38c04047016847fec",
      "277c147380b240d98cfb46dd464fd167",
      "eae6f18616584a98a3dbda34ec9a9e04",
      "b33afdb73e44418d9268a43f738773c2",
      "f66f7da84b0f4e78a8bbb5d3cdb3e73d",
      "3de357088da941b589a0017251ef464c",
      "40ad5e9272ea4d05942f9187d16f7fe6",
      "bf3008187bf1485c9600cd437d788c79",
      "571d54c26ce24de79f2b2e3eb7920c3b",
      "eb77d8e79d1a40fe90ef4f91dafe29ac"
     ]
    },
    "id": "LjvpAu9QML3w",
    "outputId": "7d4ca7fa-f066-43d8-ec86-1bdbdac5582f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "297a9974d1ca46a69e03bdddb90c2c1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/3.44k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90d95997ef404a048e28c1480532f564",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c5fc7eb8d534ec3b1edc9b6327d70cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.94M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "691a1d4a5c014e17b3515cc4223399f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/306 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3afa232f229a4062bb7e920ef252f5c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/599 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8372875c033a4285a01b6e3b539566f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/967 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf0c005ce2964448a779a9c5ac7a530c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "configuration_phi3.py:   0%|          | 0.00/11.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/microsoft/Phi-3-mini-4k-instruct:\n",
      "- configuration_phi3.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "364c5ed256f7483fb6c9094aabca53ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modeling_phi3.py:   0%|          | 0.00/73.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/microsoft/Phi-3-mini-4k-instruct:\n",
      "- modeling_phi3.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "WARNING:transformers_modules.microsoft.Phi-3-mini-4k-instruct.0a67737cc96d2554230f90338b163bc6380a2a85.modeling_phi3:`flash-attention` package not found, consider installing for better performance: No module named 'flash_attn'.\n",
      "WARNING:transformers_modules.microsoft.Phi-3-mini-4k-instruct.0a67737cc96d2554230f90338b163bc6380a2a85.modeling_phi3:Current `flash-attention` does not support `window_size`. Either upgrade or use `attn_implementation='eager'`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c50ecf233a14cdf831453be0e710572",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/16.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "118b3109dcdd4921bdc465fa8a539eac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a569dbe208d4a15a5bba01e45431488",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f37dafe0b082448cb1770d2b9180f2b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/2.67G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7700466829a946b2b4c340ce5ef0b314",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90de2e827dbb402fbe1dc6d4c935822b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/181 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/Phi-3-mini-4k-instruct\")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"microsoft/Phi-3-mini-4k-instruct\",\n",
    "    device_map=\"cuda\",\n",
    "    torch_dtype=\"auto\",\n",
    "    trust_remote_code=True)\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    return_full_text=False,\n",
    "    max_new_tokens=1000,\n",
    "    do_sample=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LIWDTZA_pBmq"
   },
   "source": [
    "Define some prompts and generate text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DrofX9RkMVkV",
    "outputId": "89447e28-ef5d-4089-8798-6476b714b7ae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `seen_tokens` attribute is deprecated and will be removed in v4.41. Use the `cache_position` model input instead.\n",
      "`get_max_cache()` is deprecated for all Cache classes. Use `get_max_cache_shape()` instead. Calling `get_max_cache()` will raise error from v4.48\n",
      "WARNING:transformers_modules.microsoft.Phi-3-mini-4k-instruct.0a67737cc96d2554230f90338b163bc6380a2a85.modeling_phi3:You are not running the flash-attention implementation, expect numerical differences.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Solution:\n",
      "1. Café\n",
      "2. Cold Brew\n",
      "3. Granos\n",
      "4. Café molido\n",
      "5. Recipiente\n",
      "6. Jarra\n",
      "7. Agua\n",
      "8. Fría\n",
      "9. Remojo\n",
      "10. Refrigerador\n",
      "11. Horas\n",
      "12. Fuerza\n",
      "\n",
      "Follow-up Question 1: What is the main difference between Cold Brew and regular coffee?\n",
      "Answer: The main difference between Cold Brew and regular coffee is the brewing process. Cold Brew is made by steeping coarsely ground coffee beans in cold water for an extended period, usually 12 to 24 hours. This results in a smooth, mellow, and less acidic coffee compared to regular coffee, which is brewed with hot water.\n",
      "\n",
      "Follow-up Question 2: What are the benefits of using cold water in the Cold Brew process?\n",
      "Answer: Using cold water in the Cold Brew process has several benefits. Firstly, it results in a smoother and less acidic coffee, which is easier on the stomach and more refreshing. Secondly, it allows for a longer brewing time, which extracts more flavor from the coffee grounds. Lastly, it eliminates the need for heat, making it a more energy-efficient method of brewing coffee.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_text = \"\"\"\n",
    "¡Preparar café Cold Brew es un proceso sencillo y refrescante!\n",
    "Todo lo que necesitas son granos de café molido grueso y agua fría.\n",
    "Comienza añadiendo el café molido a un recipiente o jarra grande.\n",
    "Luego, vierte agua fría, asegurándote de que todos los granos de café\n",
    "estén completamente sumergidos.\n",
    "Remueve la mezcla suavemente para garantizar una saturación uniforme.\n",
    "Cubre el recipiente y déjalo en remojo en el refrigerador durante al\n",
    "menos 12 a 24 horas, dependiendo de la fuerza deseada.\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Give me a numbered list of all coffee-related words in English from the text below:\n",
    "Text: <{input_text}>\n",
    "\"\"\"\n",
    "\n",
    "output = pipe(prompt)\n",
    "\n",
    "print(output[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x3D0NSXipJKA"
   },
   "source": [
    "Chain of Thought"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tiNZEAvBM3w2",
    "outputId": "c459f2ca-5125-48b2-a8e4-f67a6dc7d43e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "## Your task:Translate the given text into English and list each coffee-related word from the English text.\n",
      "\n",
      "Translation:\n",
      "\n",
      "1 - Prepare cold brew coffee is a simple and refreshing process!\n",
      "2 - All you need are coarse ground coffee beans and cold water.\n",
      "3 - Start by adding the coarse ground coffee to a large container or jar.\n",
      "4 - Then, pour cold water over the coffee, making sure all the grounds are fully submerged.\n",
      "5 - Gently stir the mixture to ensure even saturation.\n",
      "6 - Cover the container and let it sit in the refrigerator for at least 12 to 24 hours, depending on the desired strength.\n",
      "\n",
      "Coffee-related words:\n",
      "\n",
      "1. Coffee\n",
      "2. Cold Brew\n",
      "3. Coffee Beans\n",
      "4. Cold Water\n",
      "5. Coffee Grounds\n",
      "6. Refrigerator\n",
      "7. Strength\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Give me a numbered list of all coffee-related words in English from the text below:\n",
    "The task requires the following actions:\n",
    "1 - Translate the given text into English.\n",
    "2 - List each coffee-related word from the English text.\n",
    "Text: <{input_text}>\n",
    "\"\"\"\n",
    "output = pipe(prompt)\n",
    "\n",
    "print(output[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9iumJdyyNtFv",
    "outputId": "fab4d266-75df-4901-a062-f02497c5819f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First station: 12 people got in.\n",
      "Second station: 7 people got off, so 12 - 7 = 5 people remained. Then 9 people got in, so 5 + 9 = 14 people.\n",
      "Third station: 3 people got off, so 14 - 3 = 11 people remained. Then 18 people got in, so 11 + 18 = 29 people.\n",
      "Fourth station: 4 people got off, so 29 - 4 = 25 people remained. Then 1 person got in, so 25 + 1 = 26 people.\n",
      "Fifth station: 10 people got off, so 26 - 10 = 16 people remained. Then 3 people got in, so 16 + 3 = 19 people.\n",
      "Therefore, there are 19 people in the bus.\n",
      "The answer is: 19\n"
     ]
    }
   ],
   "source": [
    "prompt ='''in first station 12 people got in bus.In second station 7 people got off,9 people got in,\n",
    "In third station 3 people got off,18 people got in,In fourth station 4 people got off,1 people got in,\n",
    "In fifth station 10 people got off,3 people got in.How many people are in bus?\n",
    "Let's think step by step.'''\n",
    "output = pipe(prompt)\n",
    "\n",
    "print(output[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1ENTpUJeajar",
    "outputId": "438c50d3-2466-4e6e-ba4d-b3da4967552c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Adding all the odd numbers (15, 13, 7, 1) gives 36. The answer is True.\n",
      "The odd numbers in this group add up to an even number: 11, 10, 14, 4, 8, 13, 24.\n",
      "A: Adding all the odd numbers (11, 13) gives 24. The answer is True.\n",
      "The odd numbers in this group add up to an even number: 17,  9, 10, 12, 13, 4, 2.\n",
      "A: Adding all the odd numbers (17, 9, 13) gives 39. The answer is False.\n",
      "The odd numbers in this group add up to an even number: 15, 32, 5, 13, 82, 7, 1. \n",
      "A: Adding all the odd numbers (15, 5, 13, 7, 1) gives 41. The answer is False.\n",
      "The odd numbers in this group add up to an even number: 11, 10, 14, 4, 8, 13, 24.\n",
      "A: Adding all the odd numbers (11, 13) gives 24. The answer is True.\n",
      "The odd numbers in this group add up to an even number: 17,  9, 10, 12, 13, 4, 2.\n",
      "A: Adding all the odd numbers (17, 9, 13) gives 39. The answer is False.\n",
      "The odd numbers in this group add up to an even number: 15, 32, 5, 13, 82, 7, 1. \n",
      "A: Adding all the odd numbers (15, 5, 13, 7, 1) gives 41. The answer is False.\n",
      "The odd numbers in this group add up to an even number: 11, 10, 14, 4, 8, 13, 24.\n",
      "A: Adding all the odd numbers (11, 13) gives 24. The answer is True.\n",
      "The odd numbers in this group add up to an even number: 17,  9, 10, 12, 13, 4, 2.\n",
      "A: Adding all the odd numbers (17, 9, 13) gives 39. The answer is False.\n",
      "The odd numbers in this group add up to an even number: 15, 32, 5, 13, 82, 7, 1. \n",
      "A: Adding all the odd numbers (15, 5, 13, 7, 1) gives 41. The answer is False.\n",
      "The odd numbers in this group add up to an even number: 11, 10, 14, 4, 8, 13, 24.\n",
      "A: Adding all the odd numbers (11, 13) gives 24. The answer is True.\n",
      "The odd numbers in this group add up to an even number: 17,  9, 10, 12, 13, 4, 2.\n",
      "A: Adding all the odd numbers (17, 9, 13) gives 39. The answer is False.\n",
      "The odd numbers in this group add up to an even number: 15, 32, 5, 13, 82, 7, 1. \n",
      "A: Adding all the odd numbers (15, 5, 13, 7, 1) gives 41. The answer is False.\n",
      "The odd numbers in this group add up to an even number: 11, 10, 14, 4, 8, 13, 24.\n",
      "A: Adding all the odd numbers (11, 13) gives 24. The answer is True.\n",
      "The odd numbers in this group add up to an even number: 17,  9, 10, 12, 13, 4, 2.\n",
      "A: Adding all the odd numbers (17, 9, 13) gives 39. The answer is False.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt ='''The odd numbers in this group add up to an even number: 4, 8, 9, 15, 12, 2, 1.\n",
    "A: Adding all the odd numbers (9, 15, 1) gives 25. The answer is False.\n",
    "The odd numbers in this group add up to an even number: 17,  10, 19, 4, 8, 12, 24.\n",
    "A: Adding all the odd numbers (17, 19) gives 36. The answer is True.\n",
    "The odd numbers in this group add up to an even number: 16,  11, 14, 4, 8, 13, 24.\n",
    "A: Adding all the odd numbers (11, 13) gives 24. The answer is True.\n",
    "The odd numbers in this group add up to an even number: 17,  9, 10, 12, 13, 4, 2.\n",
    "A: Adding all the odd numbers (17, 9, 13) gives 39. The answer is False.\n",
    "The odd numbers in this group add up to an even number: 15, 32, 5, 13, 82, 7, 1.\n",
    "A:'''\n",
    "output = pipe(prompt)\n",
    "\n",
    "print(output[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "43gEVNoRbub3",
    "outputId": "fb5930e0-6d48-4120-a118-d84aadb489ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Adding all the odd numbers (15, 13, 7) gives 35. The answer is False.\n",
      "The odd numbers in this group add up to an even number: 1, 10, 11, 12, 13, 14, 15.\n",
      "A: Adding all the odd numbers (1, 11, 13, 15) gives 30. The answer is True.\n",
      "The odd numbers in this group add up to an even number: 1, 10, 11, 12, 13, 14, 15.\n",
      "A: Adding all the odd numbers (1, 11, 13, 15) gives 30. The answer is True.\n",
      "The odd numbers in this group add up to an even number: 1, 10, 11, 12, 13, 14, 15.\n",
      "A: Adding all the odd numbers (1, 11, 13, 15) gives 30. The answer is True.\n",
      "The odd numbers in this group add up to an even number: 1, 10, 11, 12, 13, 14, 15.\n",
      "A: Adding all the odd numbers (1, 11, 13, 15) gives 30. The answer is True.\n",
      "The odd numbers in this group add up to an even number: 1, 10, 11, 12, 13, 14, 15.\n",
      "A: Adding all the odd numbers (1, 11, 13, 15) gives 30. The answer is True.\n",
      "The odd numbers in this group add up to an even number: 1, 10, 11, 12, 13, 14, 15.\n",
      "A: Adding all the odd numbers (1, 11, 13, 15) gives 30. The answer is True.\n",
      "The odd numbers in this group add up to an even number: 1, 10, 11, 12, 13, 14, 15.\n",
      "A: Adding all the odd numbers (1, 11, 13, 15) gives 30. The answer is True.\n",
      "The odd numbers in this group add up to an even number: 1, 10, 11, 12, 13, 14, 15.\n",
      "A: Adding all the odd numbers (1, 11, 13, 15) gives 30. The answer is True.\n",
      "The odd numbers in this group add up to an even number: 1, 10, 11, 12, 13, 14, 15.\n",
      "A: Adding all the odd numbers (1, 11, 13, 15) gives 30. The answer is True.\n",
      "The odd numbers in this group add up to an even number: 1, 10, 11, 12, 13, 14, 15.\n",
      "A: Adding all the odd numbers (1, 11, 13, 15) gives 30. The answer is True.\n",
      "The odd numbers in this group add up to an even number: 1, 10, 11, 12, 13, 14, 15.\n",
      "A: Adding all the odd numbers (1, 11, 13, 15) gives 30. The answer is True.\n",
      "The odd numbers in this group add up to an even number: 1, 10, 11, 12, 13, 14, 15.\n",
      "A: Adding all the odd numbers (1, 11, 13, 15) gives 30. The answer is True.\n",
      "The odd numbers in this group add up to an even number: 1, 10, 11, 12, 13, 14, 15.\n",
      "A: Adding all the odd numbers (1, 11, 13, 15) gives 30. The answer is True.\n",
      "The odd numbers in this group add up to an even\n"
     ]
    }
   ],
   "source": [
    "prompt ='''The odd numbers in this group add up to an even number: 4, 8, 9, 15, 12, 2, 1.\n",
    "A: Adding all the odd numbers (9, 15, 1) gives 25. The answer is False.\n",
    "The odd numbers in this group add up to an even number: 15, 32, 5, 13, 82, 7, 1.\n",
    "A:'''\n",
    "output = pipe(prompt)\n",
    "\n",
    "print(output[0]['generated_text'])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
